#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Dump per-span probability dictionary for the SpanNER combiner.

Output format (pickle):
    {(sid, eid, sentid): {label: prob, ..., 'O': 0.5}}

This script runs inference on the test split and collects probability for
ALL candidate spans up to --max_spanLen generated by the dataset pipeline.

Example (AutoDL):
  python scripts/dump_span_probs.py \
    --dataname conll03 \
    --data_dir dataset/conll03 \
    --bert_config_dir bert-base-cased \
    --model_path output/best_model.pkl \
    --out_pkl combination/results/conll03/conll03_spanner_prob.pkl
"""

from __future__ import annotations

import argparse
import os
import pickle
from typing import Dict, Tuple

import torch

import sys
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)


from args_config import get_args as get_train_args  # reuse defaults for flags
from src.config_spanner import BertNerConfig
from src.bert_model_spanner import BertNER
from src.Evidential_woker import Span_Evidence
from dataloaders.spanner_dataset_msra import get_span_labels, get_loader


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Dump span probabilities for combiner")
    p.add_argument("--dataname", default="conll03")
    p.add_argument("--data_dir", required=True)
    p.add_argument("--bert_config_dir", required=True)
    p.add_argument("--model_path", required=True)
    p.add_argument("--out_pkl", required=True)
    p.add_argument("--bert_max_length", type=int, default=128)
    p.add_argument("--max_spanLen", type=int, default=5)
    p.add_argument("--gpu", type=str, default="True")
    return p.parse_args()


def main() -> None:
    args = parse_args()

    # Bootstrap a minimal training args namespace to satisfy downstream modules
    # Avoid args conflict: parse train defaults with empty argv
    argv_bak = sys.argv
    try:
        sys.argv = [sys.argv[0]]
        base = get_train_args()  # defaults only
    finally:
        sys.argv = argv_bak
    base.dataname = args.dataname
    base.data_dir = args.data_dir
    base.bert_config_dir = args.bert_config_dir
    base.bert_max_length = args.bert_max_length
    base.max_spanLen = args.max_spanLen
    base.gpu = True if str(args.gpu).lower() in ("true", "1", "yes", "y", "t") else False

    # Label/meta
    base.label2idx_list, base.morph2idx_list = get_span_labels(base)
    classes = [lab for lab, _ in base.label2idx_list if lab != 'O']
    # ensure single-sample batches for simpler unpacking
    base.batch_size = 1

    # Build model
    bert_config = BertNerConfig.from_pretrained(
        base.bert_config_dir,
        hidden_dropout_prob=base.bert_dropout,
        attention_probs_dropout_prob=base.bert_dropout,
        model_dropout=base.model_dropout,
    )
    model = torch.load(args.model_path)
    model.eval()
    if base.gpu:
        model.cuda()

    # Evidence handler to turn logits -> probabilities
    edl = Span_Evidence(base, num_classes=len(base.label2idx_list))

    # Data loader for test split
    test_loader = get_loader(base, base.data_dir, "test", False)

    span_prob: Dict[Tuple[int, int, int], Dict[str, float]] = {}
    sentid = 0
    with torch.no_grad():
        for data in test_loader:
            (
                tokens,
                token_type_ids,
                all_span_idxs_ltoken,
                morph_idxs,
                span_label_ltoken,
                all_span_lens,
                all_span_weights,
                real_span_mask_ltoken,
                words,
                all_span_word,
                all_span_idxs,
            ) = data

            if base.gpu:
                tokens = tokens.cuda()
                token_type_ids = token_type_ids.cuda()
                all_span_idxs_ltoken = all_span_idxs_ltoken.cuda()
                all_span_lens = all_span_lens.cuda()

            attention_mask = (tokens != 0).long()
            loadall = [
                tokens,
                token_type_ids,
                all_span_idxs_ltoken,
                morph_idxs,
                span_label_ltoken,
                all_span_lens,
                all_span_weights,
                real_span_mask_ltoken,
                words,
                all_span_word,
                all_span_idxs,
            ]
            logits = model(loadall, all_span_lens, all_span_idxs_ltoken, tokens, attention_mask, token_type_ids)
            predicts, _ = edl.pred(logits)  # shape: (1, n_span, n_class)
            probs = torch.softmax(predicts, dim=-1) if predicts.dim() == 3 else predicts
            probs = probs.squeeze(0).detach().cpu()  # (n_span, n_class)

            # Iterate spans (sid,eid). When batch_size==1, all_span_idxs is a list with one inner list.
            span_list = all_span_idxs[0] if isinstance(all_span_idxs, list) and len(all_span_idxs) > 0 and isinstance(all_span_idxs[0], (list, tuple)) else all_span_idxs
            for k, pair in enumerate(span_list):
                if not isinstance(pair, (list, tuple)) or len(pair) != 2:
                    # skip malformed span entry
                    continue
                sid, eid = pair
                label2prob = {lab: 0.5 for lab in classes}
                label2prob['O'] = 0.5
                if k < probs.size(0):
                    # Map by index order of label2idx_list
                    for idx, (lab, _) in enumerate(base.label2idx_list):
                        if lab == 'O':
                            continue
                        try:
                            label2prob[lab] = float(probs[k, idx].item())
                        except Exception:
                            pass
                span_prob[(int(sid), int(eid), int(sentid))] = label2prob

            sentid += 1

    os.makedirs(os.path.dirname(args.out_pkl), exist_ok=True)
    with open(args.out_pkl, 'wb') as f:
        pickle.dump(span_prob, f)
    print(f"Wrote span prob pkl: {args.out_pkl} (items={len(span_prob)})")


if __name__ == "__main__":
    main()

